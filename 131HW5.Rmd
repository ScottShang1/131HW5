---
title: "131HW5"
author: "Scott Shang (8458655)"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

---
title: "131HW5"
author: "Scott Shang (8458655)"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: pdf_document
---

```{r setup, echo=FALSE}
library(knitr)
# set global chunk options: images will be 7x5 inches
knitr::opts_chunk$set(fig.width=7, fig.height=5)
options(digits = 4)


## indents are for indenting r code as formatted text
## They may need to be adjusted depending on your OS
# if your output looks odd, increase or decrease indent
indent1 = '    '
indent2 = '        '
indent3 = '            '
```

Question1
```{r}
library("tidyverse")
library("tidymodels")
library("dplyr")
library("yardstick")
library(readr)
library(pROC)
library(discrim)
library(poissonreg)
library(corrr)
library(klaR)
library(corrplot)
library(knitr)
library(MASS)
library(ggplot2)
library(glmnet)
library(janitor)
pkm=read_csv('Pokemon.csv')
pkm
pkm=clean_names(pkm)
pkm
```
After using clean_names() on our data, it returns name with only lowercase letter, with _ as a separator, and convert symbol "#" to "number". It is helpful because it cleans up the names of variables.


Question2
```{r}
ggplot(pkm, aes(x = type_1)) +
  geom_bar()
```
There are 18 classes of the outcome. The flying type has the least numbers of Pokemon. Dark, dragon, fairy, fighting, ghost, ground, ice, poison and steel types also have less pokemon comparing to others.
```{r}
pkm=filter(pkm,type_1 %in% c("Bug","Fire","Grass","Normal","Water","Psychic"))
pkm
```
```{r}
pkm$type_1=as.factor(pkm$type_1)
pkm$legendary=as.factor(pkm$legendary)
pkm$generation=as.factor(pkm$generation)
pkm
```


Question3

```{r}
set.seed(1234)
pkm_split=initial_split(pkm,prop=0.70,strata=type_1)
train=training(pkm_split)
test=testing(pkm_split)
dim(pkm)*0.7
dim(train)
```
Yes, the training and test sets have the desired number of observations.

```{r}
folds=vfold_cv(train,v=5,strata=type_1)
folds
```
Stratifying the folds is useful because it makes sure that the folds are representative of the whole data set.


Question4
```{r}
rcp=recipe(type_1~legendary+generation+sp_atk+attack+speed+defense+hp+sp_def,data=train) %>%
  step_dummy(legendary) %>%
  step_dummy(generation) %>%
  step_normalize(all_predictors())
```


Question5
```{r}
reg=multinom_reg(mixture=tune(),penalty=tune()) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

wf=workflow() %>%
  add_recipe(rcp) %>%
  add_model(reg)

grid<-grid_regular(penalty(range = c(-5, 5)),mixture(),levels = 10)
grid
```
We will be fitting 500 models, since we have 10 levels of penalty, 10 levels of mixture, and 5 folds.

Question6
```{r}
tune_res=tune_grid(wf,resamples=folds,grid=grid)
```


```{r}
autoplot(tune_res)
```
What do you notice? Do larger or smaller values of penalty and mixture produce better accuracy and ROC AUC?

Smaller values of penalty and mixture produce better accuracy and ROC AUC. Mixture values have no strong impact when penalty is large or small, but do have better accuracy and ROC AUC for mid-range penalty.


Question7
```{r}
best=select_best(tune_res,metric="roc_auc")
final=finalize_workflow(wf,best)

final_fit=fit(final,data=train)

augment(final_fit,new_data=test) %>%
  accuracy(truth=type_1,estimate=.pred_class)
```
The performance on the testing set is pretty bad.


Question8
```{r}
augment(final_fit,new_data=test) %>%
  roc_auc(truth=type_1,estimate=.pred_Bug:.pred_Water)
```

```{r}
augment(final_fit,new_data=test) %>%
  roc_curve(truth=type_1,estimate=.pred_Bug:.pred_Water) %>%
  autoplot()

```

```{r}
augment(final_fit,new_data=test) %>%
  conf_mat(truth=type_1,estimate=.pred_class) %>%
  autoplot(type="heatmap")
```
First of all, our model doesn't perform well.
From the ROC curves, we can tell that normal type is the model best at predicting, which is also proved by the heatmap of the confusion matrix, followed by bug type and psychic type. Water type is the worst according to ROC curve, but heatmap shows different result. This might because water type has the most observations.
The reason behind the poor performance of our model might be not enough observations. With less than 100 observations per type on average, it can be hard to achieve an accurate model.
